---
---


@article{kaltenhauseretal2022,
  bibtex_show={true},
  abbr={ECSCW22},
  title={Deconstructing Gender in Asylum Categories: An Archival Perspective on a Practice with Limited Access},
  author={Kaltenhäuser, Kristin and Slaats, Tijs and Gammeltoft-Hansen, Thomas and Holten Møller, Naja},
  abstract={Public authorities make decisions that greatly impact both citizens and non-citizens. Decision-making on asylum, which is regulated by international law but administered by states, in particular is characterised by a higher level of secrecy than other public services. The 1951 Refugee Convention defnes refugeehood as the fear of being persecuted for reasons of race, religion, nationality, social group, or political opinion. Although fear of gender-related persecution was not included as one of the grounds meriting asylum, state practice means that it is today generally recognised as such. The United Nations Refugee Agency (UNHCR) recommends that states "ensure a gender-sensitive interpretation of the 1951 Refugee Convention." Using natural language processing (NLP) to analyse an open dataset of Danish asylum case summaries, we frst identify fve empirical categories connected to gender in the case summaries: 1) gender-related persecution, 2) LGBT 3) sexual conditions, 4) marital conditions and 5) other gender-related forms of persecution. Secondly, we illustrate the relationship between these gender-related categories and other categories/topics in asylum motives. Finally, we discuss how data science techniques can be applied to better understand complex, cooperative work practices in an area where access for researchers is limited, but archival data is available.},
  journal={Proceedings of the 20th European Conference on Computer-Supported Cooperative Work: The International Venue on Practice-centred Computing on the Design of Cooperation Technologies},
  year={2022},
  publisher={European Society for Socially Embedded Technologies (EUSSET)},
  doi={10.48340/ecscw2022_n03},
  html={https://dl.eusset.eu/handle/20.500.12015/4373}
},

@article{kaltenhauseretal2025,
  bibtex_show={true},
  abbr={ACMJRC25},
  title={Beyond Accuracy: Rethinking Outlier Detection in Asylum Data},
  author={Kaltenh\"{a}user, Kristin and Slaats, Tijs and Muller, Michael and Holten M\o{}ller, Naja},
  abstract = {In asylum decision-making, algorithmic tools are developed to optimize decision-making processes, for example, to streamline the application process. Accuracy, defined as correctly categorizing cases against a ground truth dataset, is a main concern. Data scientists employ outlier detection algorithms (ODA) to boost accuracy by fine-tuning datasets and discarding cases deviating from mathematical norms to prevent over-fitting. However, algorithms increasingly face scrutiny for possibly harmful effects on marginalized communities. Just as supervised machine learning is understood as a method to produce decision boundaries, ODAs are understood as methods to produce outliers – who sometimes are human beings. Organizations that use ODAs put people at risk of becoming marginalized by discarding them from a dataset, which motivates this paper. We critically engage with outlier handling as a significant juncture that molds representation within datasets. Using a dataset of asylum case summaries, we investigate the when individuals are constructed as outliers, by comparing three different ODAs and four different parameters for data modeling. This is significant because inclusion in datasets used for training automated decision tools and as ground truth, like the one under study, is crucial for ensuring transparent decisions. This study finds little overlap between the outliers constructed by the three algorithms and different data representations. This means that the outlier designation heavily depends on the choice of ODA and the parameters used in modeling the data; yet, data analysts rarely give much thought to this choice. Instead, decisions are primarily guided by technical considerations such as accuracy. Algorithms shape a specific understanding of key concepts such as text topics and norms, urging us to reconsider the design of algorithmic tools beyond merely achieving high accuracy and focusing on what makes an algorithmic decision tool useful for the particular context and the consequences for those who are constructed as outliers.},
  year = {2025},
  issue_date = {March 2025},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {2},
  number = {1},
  journal = {ACM Journal for Responsible Computing},
  doi = {10.1145/3718986},
  html = {https://doi.org/10.1145/3718986}
}



